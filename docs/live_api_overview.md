Title: Live API

URL Source: https://cloud.google.com/vertex-ai/generative-ai/docs/live-api

Published Time: Tue, 28 Oct 2025 19:31:05 GMT

Markdown Content:
Live API | Generative AI on Vertex AI | Google Cloud

===============
[Skip to main content](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#main-content)

[![Image 1: Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v154b6c17f7870ab2939b3d571919274f806798dc59971188e1f4183601ea7775/cloud/images/cloud-logo.svg)](https://cloud.google.com/)

[Technology areas](https://cloud.google.com/docs)

close

*   [AI and ML](https://cloud.google.com/docs/ai-ml)
*   [Application development](https://cloud.google.com/docs/application-development)
*   [Application hosting](https://cloud.google.com/docs/application-hosting)
*   [Compute](https://cloud.google.com/docs/compute-area)
*   [Data analytics and pipelines](https://cloud.google.com/docs/data)
*   [Databases](https://cloud.google.com/docs/databases)
*   [Distributed, hybrid, and multicloud](https://cloud.google.com/docs/dhm-cloud)
*   [Generative AI](https://cloud.google.com/docs/generative-ai)
*   [Industry solutions](https://cloud.google.com/docs/industry)
*   [Networking](https://cloud.google.com/docs/networking)
*   [Observability and monitoring](https://cloud.google.com/docs/observability)
*   [Security](https://cloud.google.com/docs/security)
*   [Storage](https://cloud.google.com/docs/storage)

[Cross-product tools](https://cloud.google.com/docs/cross-product-overviews)

close

*   [Access and resources management](https://cloud.google.com/docs/access-resources)
*   [Costs and usage management](https://cloud.google.com/docs/costs-usage)
*   [Infrastructure as code](https://cloud.google.com/docs/iac)
*   [Migration](https://cloud.google.com/docs/migration)
*   [SDK, languages, frameworks, and tools](https://cloud.google.com/docs/devtools)

[Related sites](https://cloud.google.com/)

close

*   [Google Cloud Home](https://cloud.google.com/)
*   [Free Trial and Free Tier](https://cloud.google.com/free)
*   [Architecture Center](https://cloud.google.com/architecture)
*   [Blog](https://cloud.google.com/blog)
*   [Contact Sales](https://cloud.google.com/contact)
*   [Google Cloud Developer Center](https://cloud.google.com/developers)
*   [Google Developer Center](https://developers.google.com/)
*   [Google Cloud Marketplace](https://console.cloud.google.com/marketplace)
*   [Google Cloud Marketplace Documentation](https://cloud.google.com/marketplace/docs)
*   [Google Cloud Skills Boost](https://www.cloudskillsboost.google/paths)
*   [Google Cloud Solution Center](https://cloud.google.com/solutions)
*   [Google Cloud Support](https://cloud.google.com/support-hub)
*   [Google Cloud Tech Youtube Channel](https://www.youtube.com/@googlecloudtech)

More

/

*   [English](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)
*   [Deutsch](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=de)
*   [Español](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=es)
*   [Español – América Latina](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=es-419)
*   [Français](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=fr)
*   [Indonesia](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=id)
*   [Italiano](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=it)
*   [Português](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=pt)
*   [Português – Brasil](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=pt-br)
*   [中文 – 简体](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=zh-cn)
*   [中文 – 繁體](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=zh-tw)
*   [日本語](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=ja)
*   [한국어](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=ko)

[Console](https://console.cloud.google.com/)

[Sign in](https://cloud.google.com/_d/signin?continue=https%3A%2F%2Fcloud.google.com%2Fvertex-ai%2Fgenerative-ai%2Fdocs%2Flive-api&prompt=select_account)

*   [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs)

[Guides](https://cloud.google.com/vertex-ai/generative-ai/docs)[API reference](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference)[Vertex AI Cookbook](https://cloud.google.com/vertex-ai/generative-ai/docs/cookbook)[Prompt gallery](https://cloud.google.com/vertex-ai/generative-ai/docs/prompt-gallery)[Resources](https://cloud.google.com/vertex-ai/generative-ai/docs/getting-help)[FAQ](https://cloud.google.com/vertex-ai/generative-ai/docs/faq)[Pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing)More

[Contact Us](https://cloud.google.com/contact)[Start free](https://console.cloud.google.com/freetrial)

[![Image 2: Google Cloud](https://www.gstatic.com/devrel-devsite/prod/v154b6c17f7870ab2939b3d571919274f806798dc59971188e1f4183601ea7775/cloud/images/cloud-logo.svg)](https://cloud.google.com/)

*   [Technology areas](https://cloud.google.com/docs)
    *    More 

    *   [Guides](https://cloud.google.com/vertex-ai/generative-ai/docs)
    *   [API reference](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference)
    *   [Vertex AI Cookbook](https://cloud.google.com/vertex-ai/generative-ai/docs/cookbook)
    *   [Prompt gallery](https://cloud.google.com/vertex-ai/generative-ai/docs/prompt-gallery)
    *   [Resources](https://cloud.google.com/vertex-ai/generative-ai/docs/getting-help)
    *   [FAQ](https://cloud.google.com/vertex-ai/generative-ai/docs/faq)
    *   [Pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing)

*   [Cross-product tools](https://cloud.google.com/docs/cross-product-overviews)
    *    More 

*   [Related sites](https://cloud.google.com/)
    *    More 

*   [Console](https://console.cloud.google.com/)
*   [Contact Us](https://cloud.google.com/contact)
*   [Start free](https://console.cloud.google.com/freetrial)

*   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Discover 
    *   [Overview of Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs)
    *   [Generative AI beginner's guide](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview)
    *   [Glossary](https://cloud.google.com/vertex-ai/generative-ai/docs/glossary-genai)

*   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Get started 
    *   [Get an API key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/api-keys)
    *   [Configure application default credentials](https://cloud.google.com/vertex-ai/generative-ai/docs/start/gcp-auth)
    *   [API quickstart](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstart)
    *   [Vertex AI Studio quickstart](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart)
    *   [Migrate from Google AI Studio to Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/migrate-google-ai)
    *   [Deploy your Vertex AI Studio prompt as a web application](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/deploy-vais-prompt)
    *   [Vertex AI Studio capabilities](https://cloud.google.com/vertex-ai/generative-ai/docs/start/vertex-ai-studio-capabilities)
    *   [Generate an image and verify its watermark using Imagen](https://cloud.google.com/vertex-ai/generative-ai/docs/image/quickstart-image-generate-console)
    *   [Google GenAI libraries](https://cloud.google.com/vertex-ai/generative-ai/docs/start/libraries)
    *   [Compatibility with OpenAI library](https://cloud.google.com/vertex-ai/generative-ai/docs/start/openai)
    *   Vertex AI in express mode 
    *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview)
    *   [Console tutorial](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/vertex-ai-studio-express-mode-quickstart)
    *   [API tutorial](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/vertex-ai-express-mode-api-quickstart)

*   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Select models 
    *   Model Garden 
    *   [Overview of Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)
    *   [Use models in Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/use-models)
    *   [Test model capabilities](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/quickstart)
    *   [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/available-models)
    *   Google Models 
    *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/models)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Gemini 
        *   [Gemini 2.5 Pro](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro)
        *   [Gemini 2.5 Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash)
        *   [Gemini 2.5 Flash Image](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-image)
        *   [Gemini 2.5 Flash Live API](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-live-api)
        *   [Gemini 2.5 Flash-Lite](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-lite)
        *   [Gemini 2.0 Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash)
        *   [Gemini 2.0 Flash-Lite](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash-lite)
        *   [Vertex AI Model Optimizer](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/vertex-ai-model-optimizer)
        *   [Migrate to the latest Gemini models](https://cloud.google.com/vertex-ai/generative-ai/docs/migrate)
        *   [SDKs](https://cloud.google.com/vertex-ai/generative-ai/docs/sdks/overview)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Imagen 
        *   [Imagen 3.0 Generate 002](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/3-0-generate-002)
        *   [Imagen 3.0 Generate 001](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/3-0-generate-001)
        *   [Imagen 3.0 Fast Generate 001](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/3-0-fast-generate-001)
        *   [Imagen 3.0 Capability 001](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/3-0-capability-001)
        *   [Imagen 4.0 Generate](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/4-0-generate-001)
        *   [Imagen 4.0 Fast Generate](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/4-0-fast-generate-001)
        *   [Imagen 4.0 Ultra Generate](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/4-0-ultra-generate-001)
        *   [Virtual Try-On Preview 08-04](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/virtual-try-on-preview-08-04)
        *   [Imagen product recontext preview 06-30](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/product-recontext-preview-06-30)
        *   [Migrate to Imagen 3](https://cloud.google.com/vertex-ai/generative-ai/docs/image/migrate-to-imagen-3)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Veo 
        *   [Veo 2](https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/2-0-generate-001)
        *   [Veo 2 Preview](https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/2-0-generate-preview)
        *   [Veo 2 Experimental](https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/2-0-generate-exp)
        *   [Veo 3](https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/3-0-generate-001)
        *   [Veo 3 Fast](https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/3-0-fast-generate-001)
        *   [Veo 3 preview](https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/3-0-generate-preview)
        *   [Veo 3 Fast preview](https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/3-0-fast-generate-preview)
        *   [Veo 3.1 preview](https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/3-1-generate-preview)
        *   [Veo 3.1 Fast preview](https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/3-1-fast-generate-preview)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Lyria 
        *   [Lyria 2](https://cloud.google.com/vertex-ai/generative-ai/docs/models/lyria/lyria-002)

    *   [Model versions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions)
    *   Managed models 
    *   [Model as a Service (MaaS) overview](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/overview)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Partner models 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-partner-models)
        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Claude 
            *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude)
            *   [Request predictions](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/use-claude)
            *   [Batch predictions](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/batch)
            *   [Prompt caching](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/prompt-caching)
            *   [Count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/count-tokens)
            *   [Web search](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/web-search)
            *   [Safety classifiers](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/safety)
            *   Model details 
            *   [Claude Sonnet 4.5](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/sonnet-4-5)
            *   [Claude Opus 4.1](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/opus-4-1)
            *   [Claude Haiku 4.5](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/haiku-4-5)
            *   [Claude Opus 4](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/opus-4)
            *   [Claude Sonnet 4](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/sonnet-4)
            *   [Claude 3.7 Sonnet](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/sonnet-3-7)
            *   [Claude 3.5 Haiku](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/haiku-3-5)
            *   [Claude 3 Haiku](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/haiku-3)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Mistral AI 
            *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral)
            *   Model details 
            *   [Mistral Medium 3](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/mistral-medium-3)
            *   [Mistral OCR (25.05)](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/mistral-ocr)
            *   [Mistral Small 3.1 (25.03)](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/mistral-small-3-1)
            *   [Codestral 2](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/codestral-2)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Open models 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/use-open-models)
        *   [Grant access to open models](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/grant-access-open-models)
        *   Models 
        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)DeepSeek 
            *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/deepseek)
            *   [DeepSeek-R1-0528](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/deepseek/r1-0528)
            *   [DeepSeek-V3.1](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/deepseek/deepseek-v31)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)OpenAI 
            *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/openai)
            *   [OpenAI gpt-oss-120b](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/openai/gpt-oss-120b)
            *   [OpenAI gpt-oss-20b](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/openai/gpt-oss-20b)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Qwen 
            *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/qwen)
            *   [Qwen 3 Next Instruct 80B](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/qwen/qwen3-next-instruct)
            *   [Qwen 3 Next Thinking 80B](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/qwen/qwen3-next-thinking)
            *   [Qwen 3 Coder](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/qwen/qwen3-coder)
            *   [Qwen 3 235B](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/qwen/qwen3-235b)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Embedding (e5) 
            *   [Multilingual E5 Small](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/e5/multilingual-e5-small)
            *   [Multilingual E5 Large](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/e5/multilingual-e5-large)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Llama 
            *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama)
            *   [Request predictions](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama/use-llama)
            *   Model details 
            *   [Llama 4 Maverick](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama/llama4-maverick)
            *   [Llama 4 Scout](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama/llama4-scout)
            *   [Llama 3.3](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama/llama3-3)
            *   [Llama 3.2](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama/llama3-2)
            *   [Llama 3.1 405b](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama/llama3-1-405)
            *   [Llama 3.1 70b](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama/llama3-1-70)
            *   [Llama 3.1 8b](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/llama/llama3-1-8)

        *   [Model deprecations (MaaS)](https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/partner-models)
        *   API 
        *   [Call MaaS APIs for open models](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/call-open-model-apis)
        *   [Function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/capabilities/function-calling)
        *   [Thinking](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/capabilities/thinking)
        *   [Structured output](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/capabilities/structured-output)
        *   [Batch prediction](https://cloud.google.com/vertex-ai/generative-ai/docs/maas/capabilities/batch-prediction)

    *   Self-deployed models 
    *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/self-deployed-models)
    *   [Deploy models with custom weights](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/deploy-models-with-custom-weights)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Google Gemma 
        *   [Use Gemma](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/use-gemma)
        *   [Tutorial: Deploy and inference Gemma (GPU)](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/deploy-and-inference-tutorial)
        *   [Tutorial: Deploy and inference Gemma (TPU)](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/deploy-and-inference-tutorial-tpu)

    *   [Llama](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/use-llama)
    *   [Use Hugging Face Models](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/use-hugging-face-models)
    *   [Comprehensive guide to vLLM for Text and Multimodal LLM Serving (GPU)](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/vllm/use-vllm)
    *   [vLLM TPU](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/vllm/use-vllm-tpu)
    *   [Hex-LLM](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/use-hex-llm)
    *   [xDiT](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/xdit)
    *   [Tutorial: Deploy Llamma 3 models with SpotVM and Reservations](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/spotvm-reservations/use-spotvm-reservations)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Model Garden notebooks 
        *   [Tutorial: Optimize model performance with advanced features in Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/model-garden-published-notebooks/model_garden_advanced_features)

*   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Build 
    *   Prompt design 
    *   [Introduction to prompting](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Prompting strategies 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-design-strategies)
        *   [Give clear and specific instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/clear-instructions)
        *   [Use system instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions)
        *   [Include few-shot examples](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/few-shot-examples)
        *   [Add contextual information](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/contextual-information)
        *   [Structure prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/structure-prompts)
        *   [Compare prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/compare-prompts)
        *   [Instruct the model to explain its reasoning](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/explain-reasoning)
        *   [Break down complex tasks](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/break-down-prompts)
        *   [Experiment with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values)
        *   [Prompt iteration strategies](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-iteration)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Task-specific prompt guidance 
        *   [Design multimodal prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/design-multimodal-prompts)
        *   [Design chat prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/chat/chat-prompts)
        *   [Design medical text prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/medlm/medlm-prompts)

    *   Capabilities 
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Safety 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/safety-overview)
        *   [Responsible AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/responsible-ai)
        *   [System instructions for safety](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/safety-system-instructions)
        *   [Configure content filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters)
        *   [Gemini for safety filtering and content moderation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-for-filtering-and-moderation)
        *   [Abuse monitoring](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/abuse-monitoring)
        *   [Process blocked responses](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/process-blocked-responses)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Text and code generation 
        *   [Text generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/send-chat-prompts-gemini)
        *   [System instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction)
        *   [Function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling)
        *   [Structured output](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output)
        *   [Content generation parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters)
        *   [Code execution](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/code-execution)
        *   [Medical text](https://cloud.google.com/vertex-ai/generative-ai/docs/medlm/overview)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Image generation 
        *   Gemini 
        *   [Generate images with Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/image-generation)
        *   [Edit images with Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/image-editing)
        *   Imagen 
        *   [Imagen overview](https://cloud.google.com/vertex-ai/generative-ai/docs/image/overview)
        *   [Generate images using text prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/image/generate-images)
        *   [Verify an image watermark](https://cloud.google.com/vertex-ai/generative-ai/docs/image/verify-watermark)
        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Configure Imagen parameters 
            *   [Configure Responsible AI safety settings](https://cloud.google.com/vertex-ai/generative-ai/docs/image/configure-responsible-ai-safety-settings)
            *   [Use prompt rewriter](https://cloud.google.com/vertex-ai/generative-ai/docs/image/use-prompt-rewriter)
            *   [Set text prompt language](https://cloud.google.com/vertex-ai/generative-ai/docs/image/set-text-prompt-language)
            *   [Configure aspect ratio](https://cloud.google.com/vertex-ai/generative-ai/docs/image/configure-aspect-ratio)
            *   [Set output resolution](https://cloud.google.com/vertex-ai/generative-ai/docs/image/set-output-resolution)
            *   [Omit content using a negative prompt](https://cloud.google.com/vertex-ai/generative-ai/docs/image/omit-content-using-a-negative-prompt)
            *   [Generate deterministic images](https://cloud.google.com/vertex-ai/generative-ai/docs/image/generate-deterministic-images)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Generate images for retail and e-commerce 
            *   [Generate Virtual Try-On images](https://cloud.google.com/vertex-ai/generative-ai/docs/image/generate-virtual-try-on-images)
            *   [Recontextualize product images](https://cloud.google.com/vertex-ai/generative-ai/docs/image/recontextualize-product-images)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Edit images 
            *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/image/edit-images-overview)
            *   [Insert objects into an image using inpaint](https://cloud.google.com/vertex-ai/generative-ai/docs/image/edit-insert-objects)
            *   [Remove objects from an image using inpaint](https://cloud.google.com/vertex-ai/generative-ai/docs/image/edit-remove-objects)
            *   [Expand the content of an image using outpaint](https://cloud.google.com/vertex-ai/generative-ai/docs/image/edit-outpainting)
            *   [Replace the background of an image](https://cloud.google.com/vertex-ai/generative-ai/docs/image/replace-image-background)
            *   [Edit using Personalization](https://cloud.google.com/vertex-ai/generative-ai/docs/image/edit-personalization)
            *   [Edit images using text prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/image/edit-images)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Customize images 
            *   [Subject customization](https://cloud.google.com/vertex-ai/generative-ai/docs/image/subject-customization)
            *   [Style customization](https://cloud.google.com/vertex-ai/generative-ai/docs/image/style-customization)
            *   [Controlled Customization](https://cloud.google.com/vertex-ai/generative-ai/docs/image/edit-controlled)
            *   [Instruct Customization](https://cloud.google.com/vertex-ai/generative-ai/docs/image/instruct-customization)

        *   [Upscale an image](https://cloud.google.com/vertex-ai/generative-ai/docs/image/upscale-image)
        *   [Prompt and image attribute guide](https://cloud.google.com/vertex-ai/generative-ai/docs/image/img-gen-prompt-guide)
        *   [Base64 encode and decode files](https://cloud.google.com/vertex-ai/generative-ai/docs/image/base64-encode)
        *   [Responsible AI and usage guidelines for Imagen](https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen)
        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Legacy features 
            *   [Migrate to Imagen 3](https://cloud.google.com/vertex-ai/generative-ai/docs/image/migrate-to-imagen-3)
            *   [Get image descriptions using visual captioning](https://cloud.google.com/vertex-ai/generative-ai/docs/image/image-captioning)
            *   [Use Visual Question Answering](https://cloud.google.com/vertex-ai/generative-ai/docs/image/visual-question-answering)
            *   [Get video descriptions using Imagen](https://cloud.google.com/vertex-ai/generative-ai/docs/video/video-descriptions)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Video generation 
        *   [Introduction to Veo](https://cloud.google.com/vertex-ai/generative-ai/docs/video/overview)
        *   [Generate Veo videos from text prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/video/generate-videos-from-text)
        *   [Generate Veo videos from an image](https://cloud.google.com/vertex-ai/generative-ai/docs/video/generate-videos-from-an-image)
        *   [Generate Veo videos using first and last video frames](https://cloud.google.com/vertex-ai/generative-ai/docs/video/generate-videos-from-first-and-last-frames)
        *   [Extend Veo videos](https://cloud.google.com/vertex-ai/generative-ai/docs/video/extend-a-veo-video)
        *   [Direct Veo video generation using a reference image](https://cloud.google.com/vertex-ai/generative-ai/docs/video/use-reference-images-to-guide-video-generation)
        *   [Insert objects into Veo videos](https://cloud.google.com/vertex-ai/generative-ai/docs/video/insert-objects-into-videos)
        *   [Remove objects from Veo videos](https://cloud.google.com/vertex-ai/generative-ai/docs/video/remove-objects-from-videos)
        *   [Veo prompt guide](https://cloud.google.com/vertex-ai/generative-ai/docs/video/video-gen-prompt-guide)
        *   [Turn off Veo's prompt rewriter](https://cloud.google.com/vertex-ai/generative-ai/docs/video/turn-the-prompt-rewriter-off)
        *   [Responsible AI for Veo](https://cloud.google.com/vertex-ai/generative-ai/docs/video/responsible-ai-and-usage-guidelines)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Music generation 
        *   [Generate music using Lyria](https://cloud.google.com/vertex-ai/generative-ai/docs/music/generate-music)
        *   [Lyria prompt guide](https://cloud.google.com/vertex-ai/generative-ai/docs/music/music-gen-prompt-guide)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Media analysis 
        *   [Image understanding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/image-understanding)
        *   [Video understanding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding)
        *   [Audio understanding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/audio-understanding)
        *   [Document understanding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/document-understanding)
        *   [Bounding box detection](https://cloud.google.com/vertex-ai/generative-ai/docs/bounding-box-detection)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Grounding 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview)
        *   [Grounding with Google Search](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-search)
        *   [Grounding with Google Maps](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps)
        *   [Grounding with Vertex AI Search](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-vertex-ai-search)
        *   [Grounding with your search API](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-your-search-api)
        *   [Grounding responses using RAG](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/ground-responses-using-rag)
        *   [Grounding with Elasticsearch](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-elasticsearch)
        *   [Web Grounding for Enterprise](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/web-grounding-enterprise)

    *   [URL context](https://cloud.google.com/vertex-ai/generative-ai/docs/url-context)
    *   [Thinking](https://cloud.google.com/vertex-ai/generative-ai/docs/thinking)
    *   [Computer Use](https://cloud.google.com/vertex-ai/generative-ai/docs/computer-use)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Live API 
        *   [Live API overview](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)
        *   [Best practices with Live API](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/best-practices)
        *   [Interactive conversations](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/streamed-conversations)
        *   [Built-in tools](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/tools)
        *   [Proactive audio](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/proactive-audio)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Embeddings 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings)
        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Text embeddings 
            *   [Get text embeddings](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings)
            *   [Choose an embeddings task type](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/task-types)

        *   [Get multimodal embeddings](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings)
        *   [Get batch embeddings predictions](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/batch-prediction-genai-embeddings)

    *   [Translation](https://cloud.google.com/vertex-ai/generative-ai/docs/translate/translate-text)
    *   [Generate speech from text](https://cloud.google.com/vertex-ai/generative-ai/docs/speech/text-to-speech)
    *   [Transcribe speech](https://cloud.google.com/vertex-ai/generative-ai/docs/speech/speech-to-text)
    *   Development tools 
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Use AI-powered prompt writing tools 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/ai-powered-prompt-writing)
        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Optimize prompts 
            *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer)
            *   [Zero-shot optimizer](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/zero-shot-optimizer)
            *   [Data-driven optimizer](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/data-driven-optimizer)

        *   [Use prompt templates](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-templates)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)RAG Engine 
        *   [RAG overview](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-overview)
        *   [RAG quickstart](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-quickstart)
        *   [RAG Engine billing](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-engine-billing)
        *   [Understanding RagManagedDb](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/understanding-ragmanageddb)
        *   [Data ingestion](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-data-ingestion)
        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Supported models 
            *   [Generative models](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/supported-rag-models)
            *   [Embedding models](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-embedding-models)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Document parsing 
            *   [Supported documents](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/supported-documents)
            *   [Fine-tune RAG transformations](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/fine-tune-rag-transformations)
            *   [Use Document AI layout parser](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/layout-parser-integration)
            *   [Use the LLM parser](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/llm-parser)

        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Vector database choices in RAG 
            *   [Overview of vector database choices](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/vector-db-choices)
            *   [Use RagManagedDb with RAG](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-ragmanageddb-with-rag)
            *   [Use Vertex AI Vector Search with RAG](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-vertexai-vector-search)
            *   [Use Feature Store with RAG](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-feature-store-with-rag)
            *   [Use Weaviate with RAG](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-weaviate-db)
            *   [Use Pinecone with RAG](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-pinecone)

        *   [Use Vertex AI Search with RAG](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-vertexai-search)
        *   [Reranking for RAG](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/retrieval-and-ranking)
        *   [Manage your RAG corpus](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/manage-your-rag-corpus)
        *   [Use CMEK with RAG](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-supports-cmek)
        *   [RAG quotas](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-quotas)
        *   [Use RAG in Gemini Live API](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-rag-in-multimodal-live)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Tokenizer 
        *   [List and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token)
        *   [Use the Count Tokens API](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/get-token-count)

    *   [Multimodal datasets](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/datasets)
    *   [Use Vertex AI Search](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/vertex-ai-search)
    *   Model tuning 
    *   [Introduction to tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Gemini models 
        *   [About supervised fine-tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-supervised-tuning)
        *   [Prepare your data](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-supervised-tuning-prepare)
        *   [Use supervised fine-tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-use-supervised-tuning)
        *   [Use tuning checkpoints](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tuning-checkpoints)
        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Supported modalities 
            *   [Text tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune_gemini/text_tune)
            *   [Document tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune_gemini/doc_tune)
            *   [Image tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune_gemini/image_tune)
            *   [Audio tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune_gemini/audio_tune)
            *   [Video tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune_gemini/video_tune)
            *   [Tune function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-function-calling)

    *   [Open models](https://cloud.google.com/vertex-ai/generative-ai/docs/models/open-model-tuning)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Embeddings models 
        *   [Tune text embeddings models](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-embeddings)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Imagen models 
        *   [Tune a subject model](https://cloud.google.com/vertex-ai/generative-ai/docs/image/fine-tune-model)
        *   [Create a custom style model](https://cloud.google.com/vertex-ai/generative-ai/docs/image/fine-tune-style)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Translation models 
        *   [About supervised fine-tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/translation-supervised-tuning)
        *   [Prepare your data](https://cloud.google.com/vertex-ai/generative-ai/docs/models/translation-supervised-tuning-prepare)
        *   [Use supervised fine-tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/models/translation-use-supervised-tuning)

    *   [Tuning recommendations with LoRA and QLoRA](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/lora-qlora)
    *   Migrate 
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Call Vertex AI models using OpenAI libraries 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/openai/overview)
        *   [Authenticate](https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/openai/auth-and-credentials)
        *   [Examples](https://cloud.google.com/vertex-ai/generative-ai/docs/migrate/openai/examples)

*   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Evaluate 
    *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview)
    *   [Tutorial: Perform evaluation using the console](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-genai-console)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Perform evaluation using the GenAI Client in Vertex AI SDK 
        *   [Tutorial: Evaluate models using the GenAI Client in Vertex AI SDK](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-genai-sdk)
        *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Define your evaluation metrics 
            *   [Define your evaluation metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval)
            *   [Details for managed rubric-based metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/rubric-metric-details)

        *   [Prepare your evaluation dataset](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-dataset)
        *   [Run an evaluation](https://cloud.google.com/vertex-ai/generative-ai/docs/models/run-evaluation)
        *   [View and interpret evaluation results](https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation)

    *   Alternative evaluation methods 
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Evaluate using the evaluation module in Vertex AI SDK 
        *   [Tutorial: Perform evaluation using the evaluation module in Vertex AI SDK](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-quickstart)
        *   [Define your evaluation metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/eval-python-sdk/determine-eval)
        *   [Prepare your evaluation dataset](https://cloud.google.com/vertex-ai/generative-ai/docs/models/eval-python-sdk/evaluation-dataset)
        *   [Run an evaluation](https://cloud.google.com/vertex-ai/generative-ai/docs/models/eval-python-sdk/run-evaluation)
        *   [Interpret evaluation results](https://cloud.google.com/vertex-ai/generative-ai/docs/models/eval-python-sdk/view-evaluation)
        *   [Templates for model-based metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/metrics-templates)
        *   [Evaluate agents](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-agents)
        *   [Evaluate a judge model](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluate-judge-model)
        *   [Configure a judge model](https://cloud.google.com/vertex-ai/generative-ai/docs/models/configure-judge-model)

    *   [Run AutoSxS pipeline](https://cloud.google.com/vertex-ai/generative-ai/docs/models/side-by-side-eval)
    *   [Run a computation-based evaluation pipeline](https://cloud.google.com/vertex-ai/generative-ai/docs/models/computation-based-eval-pipeline)

*   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Deploy 
    *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/deploy/overview)
    *   Optimize cost, latency, and performance 
    *   [Deployment best practices](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompt-best-practices)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Cache reused prompt context 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview)
        *   [Create a context cache](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-create)
        *   [Use a context cache](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-use)
        *   [Get context cache information](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-getinfo)
        *   [Update a context cache](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-update)
        *   [Delete a context cache](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-delete)
        *   [Context cache for fine-tuned Gemini models](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-for-tuned-gemini)

    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Batch prediction 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini)
        *   [Create batch job from Cloud Storage](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-from-cloud-storage)
        *   [Create batch job from BigQuery](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-from-bigquery)
        *   [Resume an incomplete batch job](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-resume)

    *   Quotas and system limits 
    *   [All quotas and system limits](https://cloud.google.com/vertex-ai/generative-ai/docs/quotas)
    *   [Dynamic shared quota](https://cloud.google.com/vertex-ai/generative-ai/docs/dynamic-shared-quota)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Provisioned Throughput 
        *   [Provisioned Throughput overview](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/overview)
        *   [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/supported-models)
        *   [Calculate Provisioned Throughput requirements](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/measure-provisioned-throughput)
        *   [Provisioned Throughput for Live API](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/live-api)
        *   [Single Zone Provisioned Throughput](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/szpt)
        *   [Purchase Provisioned Throughput](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/purchase-provisioned-throughput)
        *   [Use Provisioned Throughput](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/use-provisioned-throughput)
        *   [Troubleshooting error code 429](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/error-code-429)

*   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Administer 
    *   [Access control](https://cloud.google.com/vertex-ai/generative-ai/docs/access-control)
    *   [Networking](https://cloud.google.com/vertex-ai/generative-ai/docs/networking)
    *   [Security controls](https://cloud.google.com/vertex-ai/generative-ai/docs/security-controls)
    *   [Control access to Model Garden models](https://cloud.google.com/vertex-ai/generative-ai/docs/control-model-access)
    *   [Enable Data Access audit logs](https://cloud.google.com/vertex-ai/generative-ai/docs/enable-audit-logs)
    *   [Save and share prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/prompt-sharing)
    *   [Monitor models](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-observability)
    *   [Monitor cost using custom metadata labels](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/add-labels-to-api-calls)
    *   [Request-response logging](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/request-response-logging)
    *   
[](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)Secure a gen AI app by using IAP 
        *   [Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/streamlit/streamlit-genai-iap)
        *   [Set up your project and source repository](https://cloud.google.com/vertex-ai/generative-ai/docs/streamlit/setup-environment)
        *   [Create a Cloud Run service](https://cloud.google.com/vertex-ai/generative-ai/docs/streamlit/create-cloudrun-service)
        *   [Create a load balancer](https://cloud.google.com/vertex-ai/generative-ai/docs/streamlit/create-loadbalancer)
        *   [Configure IAP](https://cloud.google.com/vertex-ai/generative-ai/docs/streamlit/configure-iap)
        *   [Test your IAP-secured app](https://cloud.google.com/vertex-ai/generative-ai/docs/streamlit/view-app)
        *   [Clean up your project](https://cloud.google.com/vertex-ai/generative-ai/docs/streamlit/clean-up)

*   Go to Vertex AI documentation 
*   [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs)

*   [AI and ML](https://cloud.google.com/docs/ai-ml)
*   [Application development](https://cloud.google.com/docs/application-development)
*   [Application hosting](https://cloud.google.com/docs/application-hosting)
*   [Compute](https://cloud.google.com/docs/compute-area)
*   [Data analytics and pipelines](https://cloud.google.com/docs/data)
*   [Databases](https://cloud.google.com/docs/databases)
*   [Distributed, hybrid, and multicloud](https://cloud.google.com/docs/dhm-cloud)
*   [Generative AI](https://cloud.google.com/docs/generative-ai)
*   [Industry solutions](https://cloud.google.com/docs/industry)
*   [Networking](https://cloud.google.com/docs/networking)
*   [Observability and monitoring](https://cloud.google.com/docs/observability)
*   [Security](https://cloud.google.com/docs/security)
*   [Storage](https://cloud.google.com/docs/storage)

*   [Access and resources management](https://cloud.google.com/docs/access-resources)
*   [Costs and usage management](https://cloud.google.com/docs/costs-usage)
*   [Infrastructure as code](https://cloud.google.com/docs/iac)
*   [Migration](https://cloud.google.com/docs/migration)
*   [SDK, languages, frameworks, and tools](https://cloud.google.com/docs/devtools)

*   [Google Cloud Home](https://cloud.google.com/)
*   [Free Trial and Free Tier](https://cloud.google.com/free)
*   [Architecture Center](https://cloud.google.com/architecture)
*   [Blog](https://cloud.google.com/blog)
*   [Contact Sales](https://cloud.google.com/contact)
*   [Google Cloud Developer Center](https://cloud.google.com/developers)
*   [Google Developer Center](https://developers.google.com/)
*   [Google Cloud Marketplace](https://console.cloud.google.com/marketplace)
*   [Google Cloud Marketplace Documentation](https://cloud.google.com/marketplace/docs)
*   [Google Cloud Skills Boost](https://www.cloudskillsboost.google/paths)
*   [Google Cloud Solution Center](https://cloud.google.com/solutions)
*   [Google Cloud Support](https://cloud.google.com/support-hub)
*   [Google Cloud Tech Youtube Channel](https://www.youtube.com/@googlecloudtech)

*   On this page
*   [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#supported-models)
*   [Live API capabilities](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#live-api-capabilities)
*   [Supported audio formats](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#supported-audio-formats)
*   [Supported video formats](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#supported-video-formats)
*   [Starter examples](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#starter-examples)
    *   [Notebook tutorials](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#notebook_tutorials)
    *   [Demo applications and guides](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#demo_applications_and_guides)

*   [Additional examples](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#additional_examples)
    *   [Get text responses from audio input](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#get_text_responses_from_audio_input)
    *   [Get voice responses from text input](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#get_voice_responses_from_text_input)
    *   [Transcribe audio](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#transcribe_audio)

*   [More information](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#more_information)

*   [Home](https://cloud.google.com/)
*    [Technology areas](https://cloud.google.com/docs)
*    [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs)
*    [Documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview)

 Send feedback 
Live API
========

*   On this page
*   [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#supported-models)
*   [Live API capabilities](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#live-api-capabilities)
*   [Supported audio formats](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#supported-audio-formats)
*   [Supported video formats](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#supported-video-formats)
*   [Starter examples](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#starter-examples)
    *   [Notebook tutorials](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#notebook_tutorials)
    *   [Demo applications and guides](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#demo_applications_and_guides)

*   [Additional examples](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#additional_examples)
    *   [Get text responses from audio input](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#get_text_responses_from_audio_input)
    *   [Get voice responses from text input](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#get_voice_responses_from_text_input)
    *   [Transcribe audio](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#transcribe_audio)

*   [More information](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#more_information)

To see an example of Live API, run the "Getting Started with the Live API Native Audio" notebook in one of the following environments:

[![Image 3](https://cloud.google.com/static/vertex-ai/images/colab-logo-32px.png)Open in Colab](https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_live_api_native_audio.ipynb) | [![Image 4](https://cloud.google.com/static/vertex-ai/images/colab-enterprise-logo-32px.png)Open in Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fmultimodal-live-api%2Fintro_live_api_native_audio.ipynb) | [![Image 5](https://cloud.google.com/static/vertex-ai/images/vertex-ai-workbench-logo-32px.png)Open in Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fmultimodal-live-api%2Fintro_live_api_native_audio.ipynb) | [![Image 6](https://cloud.google.com/static/vertex-ai/images/github-logo-32px.png)View on GitHub](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_live_api_native_audio.ipynb)

The Live API enables low-latency, two-way voice and video interactions with Gemini. Use the Live API to provide end users with natural, human-like voice conversations, including the ability to interrupt the model's responses with voice commands.

This document covers the basics of using Live API, including its capabilities, starter examples, and basic use case code examples. If you're looking for information on how to start an interactive conversation using the Live API, see [Interactive conversations with the Live API](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/streamed-conversations). If you're looking for information on what tools the Live API can use, see [Built-in tools](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/tools).

[Try in Vertex AI](https://console.cloud.google.com/vertex-ai/studio/multimodal-live)

Supported models
----------------

The Live API is supported for use in both the Google Gen AI SDK and using Vertex AI Studio. Some features (like text input and output) are only available using the Gen AI SDK.

You can use the Live API with the following models:

| Model version | Availability level |
| --- | --- |
| [`gemini-live-2.5-flash`](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash#2.5-flash) | Private GA* |
| [`gemini-live-2.5-flash-preview-native-audio-09-2025`](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-live-api) | Public preview |
| [`gemini-live-2.5-flash-preview-native-audio`](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-live-api) | Public preview; Discontinuation date: October 18, 2025 |

* Reach out to your Google account team representative to request access.

For more information including technical specifications and limitations, see the [Live API reference guide](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-live).

Live API capabilities
---------------------

*   [**Real-time multimodal understanding:**](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/streamed-conversations) Converse with Gemini about what it sees on a video feed or through screen sharing, using built-in support for streaming audio and video.
*   [**Built-in tool usage:**](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/tools) Seamlessly integrate tools like [function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling) and [Grounding with Google Search](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-search) into your conversations for more practical and dynamic interactions.
*   **Low latency interactions:** Have low latency, human-like interactions with Gemini.
*   [**Multilingual support:**](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/streamed-conversations#audio-response-settings) Converse in 24 supported languages.
*   (GA versions only) **Support for [Provisioned Throughput](https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput):** Use fixed-cost, fixed-term subscription available in several term-lengths that reserves throughput for supported generative AI models on Vertex AI, including Live API.
*   **High-quality transcription:** Live API supports [text transcription](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#transcribe_audio) for both input and output audio.

Gemini 2.5 Flash with Live API also includes _native audio_ as a public preview offering. Native audio introduces:

*   [**Affective Dialog:**](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/tools#use-affective-dialog) Live API understands and responds to the user's tone of voice. The same words spoken in different ways can lead to vastly different and more nuanced conversations.
*   [**Proactive Audio and context awareness:**](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/tools#use-proactive-audio) Live API intelligently disregards ambient conversations and other irrelevant audio, understanding when to listen and when to remain silent.

For more information on native audio, see [Built-in tools](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/tools#native-audio).

Supported audio formats
-----------------------

The Live API supports the following audio formats:

*   **Input audio:** Raw 16-bit PCM audio at 16kHz, little-endian
*   **Output audio:** Raw 16-bit PCM audio at 24kHz, little-endian

Supported video formats
-----------------------

Live API supports video frames input at 1FPS. For best results, use native 768x768 resolution at 1FPS.

Starter examples
----------------

You can get started using the Live API with one of the following notebook tutorials, demo applications, or guides.

### Notebook tutorials

Download these notebook tutorials from GitHub, or open the notebook tutorials in the environment of your choice.

#### Use WebSockets with the Live API

To see an example of how to use WebSockets with the Live API, run the "Getting Started with the Live API in Vertex AI using WebSockets" notebook in one of the following environments:

[![Image 7](https://cloud.google.com/static/vertex-ai/images/colab-logo-32px.png)Open in Colab](https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_multimodal_live_api.ipynb) | [![Image 8](https://cloud.google.com/static/vertex-ai/images/colab-enterprise-logo-32px.png)Open in Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fmultimodal-live-api%2Fintro_multimodal_live_api.ipynb) | [![Image 9](https://cloud.google.com/static/vertex-ai/images/vertex-ai-workbench-logo-32px.png)Open in Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fmultimodal-live-api%2Fintro_multimodal_live_api.ipynb) | [![Image 10](https://cloud.google.com/static/vertex-ai/images/github-logo-32px.png)View on GitHub](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_multimodal_live_api.ipynb)

#### Streaming audio and video

To see an example of how to use the Live API in a streaming audio and video format, run the "Getting Started with the Live API using the Gen AI SDK" notebook in one of the following environments:

[![Image 11](https://cloud.google.com/static/vertex-ai/images/colab-logo-32px.png)Open in Colab](https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_multimodal_live_api_genai_sdk.ipynb) | [![Image 12](https://cloud.google.com/static/vertex-ai/images/colab-enterprise-logo-32px.png)Open in Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fmultimodal-live-api%2Fintro_multimodal_live_api_genai_sdk.ipynb) | [![Image 13](https://cloud.google.com/static/vertex-ai/images/vertex-ai-workbench-logo-32px.png)Open in Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fmultimodal-live-api%2Fintro_multimodal_live_api_genai_sdk.ipynb) | [![Image 14](https://cloud.google.com/static/vertex-ai/images/github-logo-32px.png)View on GitHub](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_multimodal_live_api_genai_sdk.ipynb)

### Demo applications and guides

*   [WebSocket demo app](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/multimodal-live-api/websocket-demo-app)
*   [Agent Development Kit: Custom Audio Streaming](https://google.github.io/adk-docs/streaming/custom-streaming/)
*   [Project Livewire](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/multimodal-live-api/project-livewire)

Additional examples
-------------------

To get even more utility from Live API, try these examples that use Live API's audio processing, transcription, and voice response capabilities.

### Get text responses from audio input

You can send audio and receive text responses by converting the audio to a 16-bit PCM, 16kHz, mono format. The following example reads a WAV file and sends it in the correct format:

[Python](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#python-gen-ai-sdk)More

# Test file: https://storage.googleapis.com/generativeai-downloads/data/16000.wav
# Install helpers for converting files: pip install librosa soundfile

import asyncio
import io
from pathlib import Path
from google import genai
from google.genai import types
import soundfile as sf
import librosa

client = genai.Client(
    vertexai=True,
    project=GOOGLE_CLOUD_PROJECT,
    location=GOOGLE_CLOUD_LOCATION,
)
model = "gemini-live-2.5-flash"
config = {"response_modalities": ["TEXT"]}

async def main():
    async with client.aio.live.connect(model=model, config=config) as session:

        buffer = io.BytesIO()
        y, sr = librosa.load("sample.wav", sr=16000)
        sf.write(buffer, y, sr, format="RAW", subtype="PCM_16")
        buffer.seek(0)
        audio_bytes = buffer.read()

        # If already in correct format, you can use this:
        # audio_bytes = Path("sample.pcm").read_bytes()

        await session.send_realtime_input(
            audio=types.Blob(data=audio_bytes, mime_type="audio/pcm;rate=16000")
        )

        async for response in session.receive():
            if response.text is not None:
                print(response.text)

if  __name__  == "__main__":
    asyncio.run(main())
      

### Get voice responses from text input

Use this example to send text input and receive synthesized speech responses:

[Python](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#python-gen-ai-sdk)More

import asyncio
import numpy as np
from IPython.display import Audio, Markdown, display
from google import genai
from google.genai.types import (
  Content,
  LiveConnectConfig,
  HttpOptions,
  Modality,
  Part,
  SpeechConfig,
  VoiceConfig,
  PrebuiltVoiceConfig,
)

client = genai.Client(
  vertexai=True,
  project=GOOGLE_CLOUD_PROJECT,
  location=GOOGLE_CLOUD_LOCATION,
)

voice_name = "Aoede"

config = LiveConnectConfig(
  response_modalities=["AUDIO"],
  speech_config=SpeechConfig(
      voice_config=VoiceConfig(
          prebuilt_voice_config=PrebuiltVoiceConfig(
              voice_name=voice_name,
          )
      ),
  ),
)

async with client.aio.live.connect(
  model="gemini-live-2.5-flash",
  config=config,
) as session:
  text_input = "Hello? Gemini are you there?"
  display(Markdown(f"**Input:** {text_input}"))

  await session.send_client_content(
      turns=Content(role="user", parts=[Part(text=text_input)]))

  audio_data = []
  async for message in session.receive():
      if (
          message.server_content.model_turn
          and message.server_content.model_turn.parts
      ):
          for part in message.server_content.model_turn.parts:
              if part.inline_data:
                  audio_data.append(
                      np.frombuffer(part.inline_data.data, dtype=np.int16)
                  )

  if audio_data:
      display(Audio(np.concatenate(audio_data), rate=24000, autoplay=True))
    

For more examples of sending text, see [our Getting Started guide](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/intro_multimodal_live_api_genai_sdk.ipynb).

### Transcribe audio

The Live API can transcribe both input and output audio. Use the following example to enable transcription:

[Python](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#python-gen-ai-sdk)[WebSockets](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#websockets-python)More

import asyncio
from google import genai
from google.genai import types

client = genai.Client(
    vertexai=True,
    project=GOOGLE_CLOUD_PROJECT,
    location=GOOGLE_CLOUD_LOCATION,
)
model = "gemini-live-2.5-flash"

config = {
    "response_modalities": ["AUDIO"],
    "input_audio_transcription": {},
    "output_audio_transcription": {}
}

async def main():
    async with client.aio.live.connect(model=model, config=config) as session:
        message = "Hello? Gemini are you there?"

        await session.send_client_content(
            turns={"role": "user", "parts": [{"text": message}]}, turn_complete=True
        )

        async for response in session.receive():
            if response.server_content.model_turn:
                print("Model turn:", response.server_content.model_turn)
            if response.server_content.input_transcription:
                print("Input transcript:", response.server_content.input_transcription.text)
            if response.server_content.output_transcription:
                print("Output transcript:", response.server_content.output_transcription.text)

if  __name__  == "__main__":
    asyncio.run(main())

      # Set model generation_config
CONFIG = {
    'response_modalities': ['AUDIO'],
}

headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {bearer_token[0]}",
}

# Connect to the server
async with connect(SERVICE_URL, additional_headers=headers) as ws:
    # Setup the session
    await ws.send(
        json.dumps(
            {
                "setup": {
                    "model": "gemini-2.0-flash-live-preview-04-09",
                    "generation_config": CONFIG,
                    'input_audio_transcription': {},
                    'output_audio_transcription': {}
                }
            }
        )
    )

    # Receive setup response
    raw_response = await ws.recv(decode=False)
    setup_response = json.loads(raw_response.decode("ascii"))

    # Send text message
    text_input = "Hello? Gemini are you there?"
    display(Markdown(f"**Input:** {text_input}"))

    msg = {
        "client_content": {
            "turns": [{"role": "user", "parts": [{"text": text_input}]}],
            "turn_complete": True,
        }
    }

    await ws.send(json.dumps(msg))

    responses = []
    input_transcriptions = []
    output_transcriptions = []

    # Receive chucks of server response
    async for raw_response in ws:
        response = json.loads(raw_response.decode())
        server_content = response.pop("serverContent", None)
        if server_content is None:
            break

        if (input_transcription := server_content.get("inputTranscription")) is not None:
            if (text := input_transcription.get("text")) is not None:
                input_transcriptions.append(text)
        if (output_transcription := server_content.get("outputTranscription")) is not None:
            if (text := output_transcription.get("text")) is not None:
                output_transcriptions.append(text)

        model_turn = server_content.pop("modelTurn", None)
        if model_turn is not None:
            parts = model_turn.pop("parts", None)
            if parts is not None:
                for part in parts:
                    pcm_data = base64.b64decode(part["inlineData"]["data"])
                    responses.append(np.frombuffer(pcm_data, dtype=np.int16))

        # End of turn
        turn_complete = server_content.pop("turnComplete", None)
        if turn_complete:
            break

    if input_transcriptions:
        display(Markdown(f"**Input transcription >** {''.join(input_transcriptions)}"))

    if responses:
        # Play the returned audio message
        display(Audio(np.concatenate(responses), rate=24000, autoplay=True))

    if output_transcriptions:
        display(Markdown(f"**Output transcription >** {''.join(output_transcriptions)}"))
      

Pricing for Live API transcription is determined by the number of text output tokens. To learn more, please see the [Vertex AI pricing page](https://cloud.google.com/vertex-ai/generative-ai/pricing).

More information
----------------

For more information on using the Live API, see:

*   [Best practices with the Live API](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/best-practices)
*   [Live API reference guide](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-live)
*   [Interactive conversations](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/streamed-conversations)
*   [Built-in tools](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api/tools)

 Send feedback 
Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-10-28 UTC.

 Need to tell us more?  [[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Hard to understand","hardToUnderstand","thumb-down"],["Incorrect information or sample code","incorrectInformationOrSampleCode","thumb-down"],["Missing the information/samples I need","missingTheInformationSamplesINeed","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-10-28 UTC."],[],[]] 

*   ### Why Google

    *   [Choosing Google Cloud](https://cloud.google.com/why-google-cloud/)
    *   [Trust and security](https://cloud.google.com/trust-center/)
    *   [Modern Infrastructure Cloud](https://cloud.google.com/solutions/modern-infrastructure/)
    *   [Multicloud](https://cloud.google.com/multicloud/)
    *   [Global infrastructure](https://cloud.google.com/infrastructure/)
    *   [Customers and case studies](https://cloud.google.com/customers/)
    *   [Analyst reports](https://cloud.google.com/analyst-reports/)
    *   [Whitepapers](https://cloud.google.com/whitepapers/)

*   ### Products and pricing

    *   [See all products](https://cloud.google.com/products/)
    *   [See all solutions](https://cloud.google.com/solutions/)
    *   [Google Cloud for Startups](https://cloud.google.com/startup/)
    *   [Google Cloud Marketplace](https://cloud.google.com/marketplace/)
    *   [Google Cloud pricing](https://cloud.google.com/pricing/)
    *   [Contact sales](https://cloud.google.com/contact/)

*   ### Support

    *   [Community forums](https://discuss.google.dev/c/google-cloud/14/)
    *   [Support](https://cloud.google.com/support-hub/)
    *   [Release Notes](https://docs.cloud.google.com/release-notes)
    *   [System status](https://status.cloud.google.com/)

*   ### Resources

    *   [GitHub](https://github.com/googlecloudPlatform/)
    *   [Getting Started with Google Cloud](https://docs.cloud.google.com/docs/get-started/)
    *   [Google Cloud documentation](https://docs.cloud.google.com/)
    *   [Code samples](https://docs.cloud.google.com/docs/samples)
    *   [Cloud Architecture Center](https://docs.cloud.google.com/architecture/)
    *   [Training and Certification](https://cloud.google.com/learn/training/)
    *   [Developer Center](https://cloud.google.com/developers/)

*   ### Engage

    *   [Blog](https://cloud.google.com/blog/)
    *   [Events](https://cloud.google.com/events/)
    *   [X (Twitter)](https://x.com/googlecloud)
    *   [Google Cloud on YouTube](https://www.youtube.com/googlecloud)
    *   [Google Cloud Tech on YouTube](https://www.youtube.com/googlecloudplatform)
    *   [Become a Partner](https://partners.cloud.google.com/)
    *   [Google Cloud Affiliate Program](https://cloud.google.com/affiliate-program/)
    *   [Press Corner](https://www.googlecloudpresscorner.com/)

*   [About Google](https://about.google/)
*   [Privacy](https://policies.google.com/privacy)
*   [Site terms](https://policies.google.com/terms?hl=en)
*   [Google Cloud terms](https://cloud.google.com/product-terms/)
*   [Manage cookies](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#)
*   [Our third decade of climate action: join us](https://cloud.google.com/sustainability)
*   Sign up for the Google Cloud newsletter[Subscribe](https://cloud.google.com/newsletter/)

*   [English](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)
*   [Deutsch](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=de)
*   [Español](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=es)
*   [Español – América Latina](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=es-419)
*   [Français](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=fr)
*   [Indonesia](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=id)
*   [Italiano](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=it)
*   [Português](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=pt)
*   [Português – Brasil](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=pt-br)
*   [中文 – 简体](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=zh-cn)
*   [中文 – 繁體](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=zh-tw)
*   [日本語](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=ja)
*   [한국어](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api?hl=ko)

